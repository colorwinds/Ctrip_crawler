# è¾“å…¥å‚æ•°ç¤ºä¾‹å¤§å…¨

æœ¬æ–‡æ¡£æä¾›é¡¹ç›®ä¸­æ‰€æœ‰æ¨¡å—çš„è¾“å…¥å‚æ•°ç¤ºä¾‹ã€‚

## ğŸ“‹ ç›®å½•

1. [æœç´¢æ™¯ç‚¹ID](#1-æœç´¢æ™¯ç‚¹id)
2. [è·å–æ™¯ç‚¹åˆ—è¡¨](#2-è·å–æ™¯ç‚¹åˆ—è¡¨)
3. [è·å–æ™¯ç‚¹è¯¦æƒ…](#3-è·å–æ™¯ç‚¹è¯¦æƒ…)
4. [çˆ¬å–è¯„è®º](#4-çˆ¬å–è¯„è®º)
5. [æ‰¹é‡æ“ä½œ](#5-æ‰¹é‡æ“ä½œ)

---

## 1. æœç´¢æ™¯ç‚¹ID

### è¾“å…¥å‚æ•°

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|------|
| `keyword` | str | æ˜¯ | æ™¯ç‚¹å…³é”®è¯ | "é»„é¹¤æ¥¼" |

### ä»£ç ç¤ºä¾‹

```python
from Ctrip_Spider.sight_id import SightId
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
searcher = SightId(use_user_agent_rotation=True, logger=logger)

# è¾“å…¥ç¤ºä¾‹
sight_id = searcher.search_sight_id("é»„é¹¤æ¥¼")
print(sight_id)  # è¾“å‡º: æ™¯ç‚¹ID
```

### è¾“å…¥ç¤ºä¾‹åˆ—è¡¨

```python
# ç¤ºä¾‹1: è‘—åæ™¯ç‚¹
keywords = [
    "é»„é¹¤æ¥¼",
    "æ•…å®«",
    "å¤©å®‰é—¨",
    "é•¿åŸ",
    "è¥¿æ¹–",
    "å¤–æ»©",
    "ä¸œæ–¹æ˜ç ",
]

# ç¤ºä¾‹2: åŸå¸‚åœ°æ ‡
keywords = [
    "åŒ—äº¬å¤©å›",
    "ä¸Šæµ·åŸéšåº™",
    "å¹¿å·å¡”",
    "æ·±åœ³ä¸–ç•Œä¹‹çª—",
]

# ç¤ºä¾‹3: è‡ªç„¶æ™¯è§‚
keywords = [
    "é»„å±±",
    "æ³°å±±",
    "åå±±",
    "ä¹å¯¨æ²Ÿ",
    "å¼ å®¶ç•Œ",
]
```

---

## 2. è·å–æ™¯ç‚¹åˆ—è¡¨

### è¾“å…¥å‚æ•°

| å‚æ•° | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| `district_id` | int | æ˜¯ | - | åœ°åŒºID |
| `page` | int | å¦ | 1 | é¡µç  |
| `count` | int | å¦ | 20 | æ¯é¡µæ•°é‡ |

### åœ°åŒºIDå‚è€ƒè¡¨

| åœ°åŒº | ID | è¯´æ˜ |
|------|-----|------|
| åŒ—äº¬ | 9 | é¦–éƒ½ |
| ä¸Šæµ· | 2 | ç›´è¾–å¸‚ |
| å¹¿å· | 7 | çœä¼šåŸå¸‚ |
| æ·±åœ³ | 26 | ç»æµç‰¹åŒº |
| æ­å· | 14 | çœä¼šåŸå¸‚ |
| æˆéƒ½ | 104 | çœä¼šåŸå¸‚ |
| è¥¿å®‰ | 7 | çœä¼šåŸå¸‚ |
| å—äº¬ | 6 | çœä¼šåŸå¸‚ |

### ä»£ç ç¤ºä¾‹

```python
from Ctrip_Spider.sight_list import CtripAttractionScraper
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
scraper = CtripAttractionScraper(use_user_agent_rotation=True, logger=logger)

# è¾“å…¥ç¤ºä¾‹1: è·å–å•é¡µæ•°æ®
attractions = scraper.get_attractions_list(
    district_id=9,    # åŒ—äº¬
    page=1,
    count=20
)

# è¾“å…¥ç¤ºä¾‹2: è·å–å¤šé¡µæ•°æ®
all_attractions = scraper.get_attractions_with_pagination(
    district_id=9,        # åŒ—äº¬
    pages=5,              # è·å–5é¡µ
    count_per_page=20     # æ¯é¡µ20ä¸ª
)
```

### è¾“å…¥ç¤ºä¾‹åˆ—è¡¨

```python
# ç¤ºä¾‹1: è·å–åŒ—äº¬æ™¯ç‚¹ï¼ˆç¬¬1é¡µï¼Œ20ä¸ªï¼‰
district_id = 9
page = 1
count = 20

# ç¤ºä¾‹2: è·å–ä¸Šæµ·æ™¯ç‚¹ï¼ˆç¬¬1é¡µï¼Œ10ä¸ªï¼‰
district_id = 2
page = 1
count = 10

# ç¤ºä¾‹3: è·å–å¹¿å·æ™¯ç‚¹ï¼ˆå‰3é¡µï¼Œæ¯é¡µ15ä¸ªï¼‰
district_id = 7
pages = 3
count_per_page = 15
```

---

## 3. è·å–æ™¯ç‚¹è¯¦æƒ…

### è¾“å…¥å‚æ•°

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|------|------|
| `poi_id` | int | æ˜¯ | æ™¯ç‚¹POI ID | 87211 |

### å¦‚ä½•è·å–POI IDï¼Ÿ

1. **ä»æ™¯ç‚¹åˆ—è¡¨ä¸­è·å–**: ä½¿ç”¨ `sight_list.py` è·å–æ™¯ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªæ™¯ç‚¹æœ‰ `poi_id` å­—æ®µ
2. **ä»ç½‘ç«™è·å–**: è®¿é—®æºç¨‹ç½‘ç«™ï¼ŒæŸ¥çœ‹URLä¸­çš„POI ID

### ä»£ç ç¤ºä¾‹

```python
from Ctrip_Spider.sight_detail import AttractionDetailFetcher
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
fetcher = AttractionDetailFetcher(use_user_agent_rotation=True, logger=logger)

# è¾“å…¥ç¤ºä¾‹
detail = fetcher.get_detail(87211)

if detail['success']:
    print(f"æ™¯ç‚¹åç§°: {detail['poi_name']}")
    print(f"é—¨ç¥¨ä»·æ ¼: {detail['ticket_price']}")
```

### è¾“å…¥ç¤ºä¾‹åˆ—è¡¨

```python
# ç¤ºä¾‹POI IDåˆ—è¡¨ï¼ˆéœ€è¦æ ¹æ®å®é™…æƒ…å†µè·å–ï¼‰
poi_ids = [
    87211,   # ç¤ºä¾‹POI ID 1
    76865,   # æ˜Ÿæµ·å¹¿åœº
    75628,   # æ£’æ£°å²›
    75633,   # å¤§è¿æ£®æ—åŠ¨ç‰©å›­
]

# æ‰¹é‡è·å–è¯¦æƒ…
for poi_id in poi_ids:
    detail = fetcher.get_detail(poi_id)
    if detail['success']:
        print(f"{detail['poi_name']}: {detail['ticket_price']}")
```

---

## 4. çˆ¬å–è¯„è®º

### è¾“å…¥å‚æ•°

| å‚æ•° | ç±»å‹ | å¿…å¡« | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|------|--------|------|
| `poi_id` | str | æ˜¯ | - | æ™¯ç‚¹POI IDï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰ |
| `poi_name` | str | æ˜¯ | - | æ™¯ç‚¹åç§° |
| `max_pages` | int | å¦ | 100 | æœ€å¤§çˆ¬å–é¡µæ•° |

### ä»£ç ç¤ºä¾‹

```python
from Ctrip_Spider.sight_comments import CtripCommentSpider
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
spider = CtripCommentSpider(
    output_dir='./Datasets',
    use_user_agent_rotation=True,
    logger=logger
)

# è¾“å…¥ç¤ºä¾‹
success = spider.crawl_comments(
    poi_id='76865',        # POI IDï¼ˆå­—ç¬¦ä¸²ï¼‰
    poi_name='æ˜Ÿæµ·å¹¿åœº',    # æ™¯ç‚¹åç§°
    max_pages=10           # çˆ¬å–10é¡µ
)
```

### è¾“å…¥ç¤ºä¾‹åˆ—è¡¨

```python
# ç¤ºä¾‹1: å•ä¸ªæ™¯ç‚¹
poi_id = '76865'
poi_name = 'æ˜Ÿæµ·å¹¿åœº'
max_pages = 10

# ç¤ºä¾‹2: å¤šä¸ªæ™¯ç‚¹ï¼ˆé€ä¸ªçˆ¬å–ï¼‰
pois = [
    ('76865', 'æ˜Ÿæµ·å¹¿åœº', 10),
    ('75628', 'æ£’æ£°å²›', 5),
    ('75633', 'å¤§è¿æ£®æ—åŠ¨ç‰©å›­', 8),
]

for poi_id, poi_name, max_pages in pois:
    spider.crawl_comments(poi_id, poi_name, max_pages)
```

---

## 5. æ‰¹é‡æ“ä½œ

### æ‰¹é‡çˆ¬å–è¯„è®º

```python
from Ctrip_Spider.sight_comments import CtripCommentSpider
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
spider = CtripCommentSpider(
    output_dir='./Datasets',
    use_user_agent_rotation=True,
    logger=logger
)

# è¾“å…¥: æ™¯ç‚¹åˆ—è¡¨
poi_list = [
    ['76865', 'æ˜Ÿæµ·å¹¿åœº'],
    ['75628', 'æ£’æ£°å²›'],
    ['75633', 'å¤§è¿æ£®æ—åŠ¨ç‰©å›­'],
    ['75634', 'å¤§è¿è€è™æ»©æµ·æ´‹å…¬å›­'],
]

# æ‰¹é‡çˆ¬å–
results = spider.crawl_multiple_pois(
    poi_list=poi_list,
    max_pages=10  # æ¯ä¸ªæ™¯ç‚¹çˆ¬å–10é¡µ
)

# æŸ¥çœ‹ç»“æœ
for poi, success in results.items():
    print(f"{poi}: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
```

### å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

```python
from Ctrip_Spider.sight_id import SightId
from Ctrip_Spider.sight_list import CtripAttractionScraper
from Ctrip_Spider.sight_comments import CtripCommentSpider
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("Workflow", "logs")

# æ­¥éª¤1: æœç´¢æ™¯ç‚¹ID
searcher = SightId(use_user_agent_rotation=True, logger=logger)
sight_id = searcher.search_sight_id("é»„é¹¤æ¥¼")

# æ­¥éª¤2: è·å–æ™¯ç‚¹åˆ—è¡¨ï¼Œæ‰¾åˆ°å¯¹åº”çš„POI ID
scraper = CtripAttractionScraper(use_user_agent_rotation=True, logger=logger)
attractions = scraper.get_attractions_list(district_id=9, page=1, count=50)

# æ‰¾åˆ°ç›®æ ‡æ™¯ç‚¹
target = None
for attr in attractions:
    if attr['id'] == sight_id:
        target = attr
        break

if target:
    # æ­¥éª¤3: çˆ¬å–è¯„è®º
    spider = CtripCommentSpider(
        output_dir='./Datasets',
        use_user_agent_rotation=True,
        logger=logger
    )
    spider.crawl_comments(
        poi_id=str(target['poi_id']),
        poi_name=target['name'],
        max_pages=10
    )
```

---

## ğŸ“ è¾“å…¥å‚æ•°æ€»ç»“è¡¨

### SightId (æœç´¢æ™¯ç‚¹ID)

```python
# åˆå§‹åŒ–
searcher = SightId(
    delay_range=(1, 3),              # å»¶è¿ŸèŒƒå›´ï¼ˆå¯é€‰ï¼‰
    proxies=None,                    # ä»£ç†åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    use_proxy=False,                 # æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆå¯é€‰ï¼‰
    use_user_agent_rotation=True,    # User-Agentè½®æ¢ï¼ˆæ¨èï¼‰
    logger=None                      # æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
)

# æ–¹æ³•è°ƒç”¨
sight_id = searcher.search_sight_id("å…³é”®è¯")
```

### CtripAttractionScraper (è·å–æ™¯ç‚¹åˆ—è¡¨)

```python
# åˆå§‹åŒ–
scraper = CtripAttractionScraper(
    timeout=10,                      # è¶…æ—¶æ—¶é—´ï¼ˆå¯é€‰ï¼‰
    delay_range=(1, 3),              # å»¶è¿ŸèŒƒå›´ï¼ˆå¯é€‰ï¼‰
    proxies=None,                    # ä»£ç†åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    use_proxy=False,                 # æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆå¯é€‰ï¼‰
    use_user_agent_rotation=True,    # User-Agentè½®æ¢ï¼ˆæ¨èï¼‰
    logger=None                      # æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
)

# æ–¹æ³•è°ƒç”¨
attractions = scraper.get_attractions_list(
    district_id=9,    # åœ°åŒºIDï¼ˆå¿…å¡«ï¼‰
    page=1,           # é¡µç ï¼ˆå¯é€‰ï¼Œé»˜è®¤1ï¼‰
    count=20          # æ¯é¡µæ•°é‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤20ï¼‰
)
```

### AttractionDetailFetcher (è·å–æ™¯ç‚¹è¯¦æƒ…)

```python
# åˆå§‹åŒ–
fetcher = AttractionDetailFetcher(
    delay_range=(1, 3),              # å»¶è¿ŸèŒƒå›´ï¼ˆå¯é€‰ï¼‰
    proxies=None,                    # ä»£ç†åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    use_proxy=False,                 # æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆå¯é€‰ï¼‰
    use_user_agent_rotation=True,    # User-Agentè½®æ¢ï¼ˆæ¨èï¼‰
    logger=None                      # æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
)

# æ–¹æ³•è°ƒç”¨
detail = fetcher.get_detail(87211)  # POI IDï¼ˆå¿…å¡«ï¼‰
```

### CtripCommentSpider (çˆ¬å–è¯„è®º)

```python
# åˆå§‹åŒ–
spider = CtripCommentSpider(
    output_dir='./Datasets',         # è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
    delay_range=(1, 3),              # å»¶è¿ŸèŒƒå›´ï¼ˆå¯é€‰ï¼‰
    proxies=None,                    # ä»£ç†åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    use_proxy=False,                # æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆå¯é€‰ï¼‰
    use_user_agent_rotation=True,   # User-Agentè½®æ¢ï¼ˆæ¨èï¼‰
    logger=None                     # æ—¥å¿—è®°å½•å™¨ï¼ˆå¯é€‰ï¼‰
)

# æ–¹æ³•è°ƒç”¨
success = spider.crawl_comments(
    poi_id='76865',        # POI IDï¼ˆå¿…å¡«ï¼Œå­—ç¬¦ä¸²ï¼‰
    poi_name='æ˜Ÿæµ·å¹¿åœº',    # æ™¯ç‚¹åç§°ï¼ˆå¿…å¡«ï¼‰
    max_pages=100          # æœ€å¤§é¡µæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤100ï¼‰
)
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **POI ID vs Sight ID**: 
   - `sight_id` æ˜¯æ™¯ç‚¹IDï¼Œç”¨äºæœç´¢
   - `poi_id` æ˜¯POI IDï¼Œç”¨äºè·å–è¯¦æƒ…å’Œè¯„è®º
   - ä¸¤è€…ä¸åŒï¼Œéœ€è¦åŒºåˆ†ä½¿ç”¨

2. **åœ°åŒºIDè·å–**: 
   - å¯ä»¥é€šè¿‡æµè§ˆå™¨å¼€å‘è€…å·¥å…·æŸ¥çœ‹æºç¨‹ç½‘ç«™çš„ç½‘ç»œè¯·æ±‚
   - æˆ–è€…å°è¯•ä¸åŒçš„IDå€¼

3. **å»¶è¿Ÿè®¾ç½®**: 
   - å»ºè®®è®¾ç½® `delay_range=(1, 3)` é¿å…è¯·æ±‚è¿‡å¿«
   - å¤§è§„æ¨¡çˆ¬å–å»ºè®®å¢åŠ å»¶è¿Ÿ

4. **æ•°æ®ä¿å­˜**: 
   - è¯„è®ºæ•°æ®è‡ªåŠ¨ä¿å­˜ä¸ºCSVæ ¼å¼
   - æ–‡ä»¶è·¯å¾„: `./Datasets/{poi_id}_{æ™¯ç‚¹åç§°}.csv`

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [å®Œæ•´ä½¿ç”¨ç¤ºä¾‹](main_example.py) - è¿è¡Œ `python main_example.py` æŸ¥çœ‹è¯¦ç»†ç¤ºä¾‹
- [åçˆ¬è™«ç­–ç•¥è¯´æ˜](Ctrip_Spider/ANTI_SPIDER_README.md)
- [é¡¹ç›®ä¸»README](README.md)

