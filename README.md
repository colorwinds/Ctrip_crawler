# Ctrip Data Spider & Analysis / æºç¨‹æ•°æ®çˆ¬è™«ä¸åˆ†æ

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

<a name="english"></a>
## English

### ğŸ“– Overview

This project is a comprehensive web scraping tool for collecting tourism attraction data from Ctrip (æºç¨‹), one of China's largest online travel platforms. It provides functionality to search attractions, retrieve attraction lists, fetch detailed information, and collect user reviews for data analysis and research purposes.

### ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªç”¨äºä»æºç¨‹ç½‘ï¼ˆä¸­å›½æœ€å¤§çš„åœ¨çº¿æ—…æ¸¸å¹³å°ä¹‹ä¸€ï¼‰æ”¶é›†æ—…æ¸¸æ™¯ç‚¹æ•°æ®çš„ç»¼åˆç½‘ç»œçˆ¬è™«å·¥å…·ã€‚å®ƒæä¾›äº†æœç´¢æ™¯ç‚¹ã€è·å–æ™¯ç‚¹åˆ—è¡¨ã€è·å–è¯¦ç»†ä¿¡æ¯ä»¥åŠæ”¶é›†ç”¨æˆ·è¯„è®ºç­‰åŠŸèƒ½ï¼Œç”¨äºæ•°æ®åˆ†æå’Œç ”ç©¶ã€‚

### âœ¨ Features

- **Attraction ID Search**: Search for attraction IDs by keywords
- **Attraction List Retrieval**: Get attraction lists by district/region
- **Attraction Details**: Fetch comprehensive information about specific attractions
- **Comment Scraping**: Collect user reviews and ratings in bulk
- **Anti-Spider Protection**: Built-in request optimization and User-Agent rotation
- **Data Export**: Export data in JSON and CSV formats
- **Comprehensive Logging**: Detailed logging for debugging and monitoring

### âœ¨ ä¸»è¦åŠŸèƒ½

- **æ™¯ç‚¹IDæœç´¢**: é€šè¿‡å…³é”®è¯æœç´¢æ™¯ç‚¹ID
- **æ™¯ç‚¹åˆ—è¡¨è·å–**: æŒ‰åœ°åŒºè·å–æ™¯ç‚¹åˆ—è¡¨
- **æ™¯ç‚¹è¯¦æƒ…**: è·å–ç‰¹å®šæ™¯ç‚¹çš„è¯¦ç»†ä¿¡æ¯
- **è¯„è®ºçˆ¬å–**: æ‰¹é‡æ”¶é›†ç”¨æˆ·è¯„è®ºå’Œè¯„åˆ†
- **åçˆ¬è™«ä¿æŠ¤**: å†…ç½®è¯·æ±‚ä¼˜åŒ–å’ŒUser-Agentè½®æ¢
- **æ•°æ®å¯¼å‡º**: ä»¥JSONå’ŒCSVæ ¼å¼å¯¼å‡ºæ•°æ®
- **è¯¦ç»†æ—¥å¿—**: ç”¨äºè°ƒè¯•å’Œç›‘æ§çš„è¯¦ç»†æ—¥å¿—è®°å½•

### ğŸš€ Quick Start

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### Prerequisites

- Python 3.7 or higher
- Required packages: `requests`, `beautifulsoup4`

#### ç¯å¢ƒè¦æ±‚

- Python 3.7 æˆ–æ›´é«˜ç‰ˆæœ¬
- æ‰€éœ€åŒ…: `requests`, `beautifulsoup4`

#### Installation

1. Clone the repository:
```bash
git clone https://github.com/colorwinds/Ctrip_Data_Spider_Analysis.git
cd Ctrip_Data_Spider_Analysis-main
```

2. Install dependencies:
```bash
pip install requests beautifulsoup4
```

#### å®‰è£…æ­¥éª¤

1. å…‹éš†ä»“åº“:
```bash
git clone https://github.com/colorwinds/Ctrip_Data_Spider_Analysis.git
cd Ctrip_Data_Spider_Analysis-main
```

2. å®‰è£…ä¾èµ–:
```bash
pip install requests beautifulsoup4
```

#### Basic Usage / åŸºæœ¬ä½¿ç”¨

**Quick Start Example / å¿«é€Ÿå¼€å§‹ç¤ºä¾‹:**
```bash
python quick_start.py
```

**Full Example / å®Œæ•´ç¤ºä¾‹:**
```bash
python main_example.py
```

**Test Imports / æµ‹è¯•å¯¼å…¥:**
```bash
python test_imports.py
```

### ğŸ“š Project Structure / é¡¹ç›®ç»“æ„

```
Ctrip_Data_Spider_Analysis-main/
â”‚
â”œâ”€â”€ Ctrip_Spider/              # Main spider module / ä¸»çˆ¬è™«æ¨¡å—
â”‚   â”œâ”€â”€ sight_id.py           # Attraction ID search / æ™¯ç‚¹IDæœç´¢
â”‚   â”œâ”€â”€ sight_list.py         # Attraction list retrieval / æ™¯ç‚¹åˆ—è¡¨è·å–
â”‚   â”œâ”€â”€ sight_detail.py       # Attraction detail fetching / æ™¯ç‚¹è¯¦æƒ…è·å–
â”‚   â”œâ”€â”€ sight_comments.py     # Comment scraping / è¯„è®ºçˆ¬å–
â”‚   â”œâ”€â”€ anti_spider.py        # Anti-spider protection / åçˆ¬è™«ä¿æŠ¤
â”‚   â”œâ”€â”€ log.py                # Logging utilities / æ—¥å¿—å·¥å…·
â”‚   â””â”€â”€ config.py             # Configuration / é…ç½®æ–‡ä»¶
â”‚
â”œâ”€â”€ Datasets/                  # Output directory for scraped data / çˆ¬å–æ•°æ®è¾“å‡ºç›®å½•
â”œâ”€â”€ logs/                      # Log files / æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ utils/                     # Utility functions / å·¥å…·å‡½æ•°
â”‚
â”œâ”€â”€ main_example.py            # Complete usage examples / å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ quick_start.py             # Quick start guide / å¿«é€Ÿå¼€å§‹æŒ‡å—
â”œâ”€â”€ test_imports.py            # Import testing / å¯¼å…¥æµ‹è¯•
â”‚
â”œâ”€â”€ README.md                  # This file / æœ¬æ–‡ä»¶
â”œâ”€â”€ main_example.py            # Complete usage examples / å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
â””â”€â”€ INPUT_EXAMPLES.md          # Input parameter examples / è¾“å…¥å‚æ•°ç¤ºä¾‹
```

### ğŸ”§ Usage Examples

### ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

#### Example 1: Search Attraction ID / ç¤ºä¾‹1: æœç´¢æ™¯ç‚¹ID

```python
from Ctrip_Spider.sight_id import SightId
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
searcher = SightId(
    delay_range=(1, 2),
    use_user_agent_rotation=True,
    logger=logger
)

# Search for attraction ID by keyword / é€šè¿‡å…³é”®è¯æœç´¢æ™¯ç‚¹ID
sight_id = searcher.search_sight_id("Yellow Crane Tower")  # or "é»„é¹¤æ¥¼"
print(f"Attraction ID: {sight_id}")  # æ™¯ç‚¹ID
```

#### Example 2: Get Attraction List / ç¤ºä¾‹2: è·å–æ™¯ç‚¹åˆ—è¡¨

```python
from Ctrip_Spider.sight_list import CtripAttractionScraper
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
scraper = CtripAttractionScraper(
    timeout=10,
    delay_range=(1, 2),
    use_user_agent_rotation=True,
    logger=logger
)

# Get attractions from Beijing (district_id=9) / è·å–åŒ—äº¬åœ°åŒºçš„æ™¯ç‚¹ï¼ˆdistrict_id=9ï¼‰
attractions = scraper.get_attractions_with_pagination(
    district_id=9,      # Beijing / åŒ—äº¬
    pages=2,            # Number of pages / é¡µæ•°
    count_per_page=5    # Count per page / æ¯é¡µæ•°é‡
)
```

#### Example 3: Fetch Attraction Details / ç¤ºä¾‹3: è·å–æ™¯ç‚¹è¯¦æƒ…

```python
from Ctrip_Spider.sight_detail import AttractionDetailFetcher
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
fetcher = AttractionDetailFetcher(
    delay_range=(1, 2),
    use_user_agent_rotation=True,
    logger=logger
)

# Fetch attraction details by POI ID / é€šè¿‡POI IDè·å–æ™¯ç‚¹è¯¦æƒ…
detail = fetcher.get_detail(poi_id=87211)
if detail.get('success'):
    print(f"Name: {detail.get('poi_name')}")           # æ™¯ç‚¹åç§°
    print(f"Price: {detail.get('ticket_price')}")     # é—¨ç¥¨ä»·æ ¼
```

#### Example 4: Scrape Comments / ç¤ºä¾‹4: çˆ¬å–è¯„è®º

```python
from Ctrip_Spider.sight_comments import CtripCommentSpider
from Ctrip_Spider.log import CtripSpiderLogger

logger = CtripSpiderLogger("MySpider", "logs")
spider = CtripCommentSpider(
    output_dir='./Datasets',    # Output directory / è¾“å‡ºç›®å½•
    delay_range=(1, 2),
    use_user_agent_rotation=True,
    logger=logger
)

# Scrape comments for an attraction / çˆ¬å–æ™¯ç‚¹è¯„è®º
success = spider.crawl_comments(
    poi_id='76865',                    # POI ID (string) / POI IDï¼ˆå­—ç¬¦ä¸²ï¼‰
    poi_name='Xinghai Square',         # Attraction name / æ™¯ç‚¹åç§° (e.g., 'æ˜Ÿæµ·å¹¿åœº')
    max_pages=10                       # Maximum pages to scrape / æœ€å¤§çˆ¬å–é¡µæ•°
)
```

### ğŸ“Š Output Data Format / è¾“å‡ºæ•°æ®æ ¼å¼

#### Attraction List (JSON) / æ™¯ç‚¹åˆ—è¡¨ (JSON)
- **File / æ–‡ä»¶**: `attractions_list.json`
- **Fields / å­—æ®µ**: nameï¼ˆåç§°ï¼‰, idï¼ˆIDï¼‰, poi_idï¼ˆPOI IDï¼‰, ratingï¼ˆè¯„åˆ†ï¼‰, review_countï¼ˆè¯„è®ºæ•°ï¼‰, priceï¼ˆä»·æ ¼ï¼‰, addressï¼ˆåœ°å€ï¼‰ç­‰

#### Comments (CSV) / è¯„è®ºæ•°æ® (CSV)
- **File / æ–‡ä»¶**: `{poi_id}_{attraction_name}.csv` / `{poi_id}_{æ™¯ç‚¹åç§°}.csv`
- **Fields / å­—æ®µ**: Comment IDï¼ˆè¯„è®ºIDï¼‰, User Nameï¼ˆç”¨æˆ·æ˜µç§°ï¼‰, Ratingï¼ˆæ€»ä½“è¯„åˆ†ï¼‰, Comment Contentï¼ˆè¯„è®ºå†…å®¹ï¼‰, Post Timeï¼ˆå‘å¸ƒæ—¶é—´ï¼‰, Useful Countï¼ˆæœ‰ç”¨æ•°ï¼‰, Reply Countï¼ˆå›å¤æ•°ï¼‰, Travel Typeï¼ˆå‡ºè¡Œç±»å‹ï¼‰, User Locationï¼ˆç”¨æˆ·æ‰€åœ¨åœ°ï¼‰, Play Durationï¼ˆæ¸¸ç©æ—¶é•¿ï¼‰, Image Countï¼ˆå›¾ç‰‡æ•°é‡ï¼‰, Image URLsï¼ˆå›¾ç‰‡é“¾æ¥åˆ—è¡¨ï¼‰, Scenic Ratingï¼ˆæ™¯è‰²è¯„åˆ†ï¼‰, Fun Ratingï¼ˆè¶£å‘³è¯„åˆ†ï¼‰, Value Ratingï¼ˆæ€§ä»·æ¯”è¯„åˆ†ï¼‰, Recommended Itemsï¼ˆæ¨èé¡¹ç›®ï¼‰

### âš™ï¸ Configuration

### âš™ï¸ é…ç½®è¯´æ˜

#### Delay Settings / å»¶è¿Ÿè®¾ç½®
```python
delay_range=(1, 3)  # Request delay range in seconds / è¯·æ±‚å»¶è¿ŸèŒƒå›´ï¼ˆç§’ï¼‰
```

#### User-Agent Rotation / User-Agentè½®æ¢
```python
use_user_agent_rotation=True  # Recommended / æ¨èå¯ç”¨
```

#### Proxy Support (Optional) / ä»£ç†æ”¯æŒï¼ˆå¯é€‰ï¼‰
```python
proxies = [
    'http://proxy1.example.com:8080',
    'http://proxy2.example.com:8080',
]
use_proxy=True  # Enable proxy / å¯ç”¨ä»£ç†
```

### ğŸ—ºï¸ Common District IDs

### ğŸ—ºï¸ å¸¸è§åœ°åŒºIDå‚è€ƒ

| District | ID |
|----------|-----|
| Beijing  | 9   |
| Shanghai | 2   |
| Guangzhou| 7   |
| Shenzhen | 26  |
| Hangzhou | 14  |
| Chengdu  | 104 |
| Xi'an    | 7   |
| Nanjing  | 6   |

| åœ°åŒº | ID |
|------|-----|
| åŒ—äº¬ | 9   |
| ä¸Šæµ· | 2   |
| å¹¿å· | 7   |
| æ·±åœ³ | 26  |
| æ­å· | 14  |
| æˆéƒ½ | 104 |
| è¥¿å®‰ | 7   |
| å—äº¬ | 6   |

### âš ï¸ Important Notes

1. **Compliance**: Please comply with the website's robots.txt and terms of service
2. **Rate Limiting**: Set reasonable delay ranges (1-3 seconds) to avoid overloading servers
3. **Data Usage**: Scraped data is for learning and research purposes only
4. **Error Handling**: Monitor log files for debugging
5. **Proxy Usage**: Ensure proxy availability if using proxies

### âš ï¸ é‡è¦æç¤º

1. **éµå®ˆåè®®**: è¯·éµå®ˆç½‘ç«™çš„robots.txtå’Œä½¿ç”¨åè®®
2. **åˆç†é¢‘ç‡**: è®¾ç½®åˆç†çš„å»¶è¿ŸèŒƒå›´ï¼ˆ1-3ç§’ï¼‰ä»¥é¿å…æœåŠ¡å™¨è¿‡è½½
3. **æ•°æ®ä½¿ç”¨**: çˆ¬å–çš„æ•°æ®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨
4. **é”™è¯¯å¤„ç†**: ç›‘æ§æ—¥å¿—æ–‡ä»¶ä»¥è¿›è¡Œè°ƒè¯•
5. **ä»£ç†ä½¿ç”¨**: å¦‚æœä½¿ç”¨ä»£ç†ï¼Œè¯·ç¡®ä¿ä»£ç†å¯ç”¨

### ğŸ› Troubleshooting

**Q: Cannot retrieve data?**
- Check network connection
- Review log files for error details
- Try increasing delay time
- Check if access is restricted

**Q: Comment scraping failed?**
- Verify POI ID is correct
- Check if the attraction has comments
- Review log files for specific errors

**Q: How to get more district IDs?**
- Use browser developer tools to inspect network requests on Ctrip website
- Or try different district_id values using `sight_list.py`

### ğŸ› å¸¸è§é—®é¢˜

**Q: æ— æ³•è·å–æ•°æ®ï¼Ÿ**
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£é”™è¯¯è¯¦æƒ…
- å°è¯•å¢åŠ å»¶è¿Ÿæ—¶é—´
- æ£€æŸ¥æ˜¯å¦è¢«é™åˆ¶è®¿é—®

**Q: è¯„è®ºçˆ¬å–å¤±è´¥ï¼Ÿ**
- ç¡®è®¤POI IDæ˜¯å¦æ­£ç¡®
- æ£€æŸ¥æ™¯ç‚¹æ˜¯å¦æœ‰è¯„è®º
- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£å…·ä½“é”™è¯¯

**Q: å¦‚ä½•è·å–æ›´å¤šåœ°åŒºIDï¼Ÿ**
- ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·æŸ¥çœ‹æºç¨‹ç½‘ç«™çš„ç½‘ç»œè¯·æ±‚
- æˆ–ä½¿ç”¨ `sight_list.py` å°è¯•ä¸åŒçš„district_idå€¼

### ğŸ“– Documentation

- [Complete Usage Examples](main_example.py) - Run `python main_example.py` for detailed examples
- [Input Parameter Examples](INPUT_EXAMPLES.md)
- [Anti-Spider Strategy](Ctrip_Spider/ANTI_SPIDER_README.md)

### ğŸ“– ç›¸å…³æ–‡æ¡£

- [å®Œæ•´ä½¿ç”¨ç¤ºä¾‹](main_example.py) - è¿è¡Œ `python main_example.py` æŸ¥çœ‹è¯¦ç»†ç¤ºä¾‹
- [è¾“å…¥å‚æ•°ç¤ºä¾‹](INPUT_EXAMPLES.md)
- [åçˆ¬è™«ç­–ç•¥è¯´æ˜](Ctrip_Spider/ANTI_SPIDER_README.md)

### ğŸ“ License

This project is for educational and research purposes only. Please respect the website's terms of service and use responsibly.

### ğŸ“ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›æ•™è‚²å’Œç ”ç©¶ä½¿ç”¨ã€‚è¯·å°Šé‡ç½‘ç«™çš„æœåŠ¡æ¡æ¬¾å¹¶è´Ÿè´£ä»»åœ°ä½¿ç”¨ã€‚

### ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤ Pull Requestã€‚

---

<a name="ä¸­æ–‡"></a>
## ä¸­æ–‡

*Note: The Chinese section above contains all Chinese translations. This section is kept for navigation purposes.*

*æ³¨ï¼šä¸Šæ–¹çš„ä¸­æ–‡éƒ¨åˆ†å·²åŒ…å«æ‰€æœ‰ä¸­æ–‡ç¿»è¯‘ã€‚æ­¤éƒ¨åˆ†ä¿ç•™ç”¨äºå¯¼èˆªç›®çš„ã€‚*

---

## ğŸ“§ Contact / è”ç³»æ–¹å¼

If you have any questions or suggestions, please feel free to open an issue.

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·éšæ—¶æäº¤ issueã€‚
